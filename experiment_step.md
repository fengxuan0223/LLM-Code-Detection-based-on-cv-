1. **å®éªŒ 1ï¼šLoss æ›²çº¿**
2. **å®éªŒ 2ï¼šBackbone å¯¹æ¯”**
3. **å®éªŒ 3ï¼šFrozen vs Finetune CodeBERT**
4. **æ•´ç†ç»“æœè¡¨ + å†™å®éªŒåˆ†æ**

------

# âœ… Step 1ï¼šå®Œæˆå®éªŒ 1 â€”â€” Loss æ›²çº¿



âœ… **å®éªŒ 1 åˆ°æ­¤ä¸ºæ­¢ï¼Œç»“æŸã€‚**

------

# âœ… Step 2ï¼šå®éªŒ 2 â€”â€” Backbone å¯¹æ¯”ï¼ˆæœ€å…³é”®ï¼‰

1ï¸âƒ£ SimpleMLPï¼ˆbaselineï¼‰

```bash
python train.py \
  --arch simplemlp \
  --dataroot ./code_dataset \
  --gpu_ids -1 \
  --niter 10 \
  --name exp_simplemlp
```

------

## 2ï¸âƒ£ BiLSTMï¼ˆå¦‚æœä½ é¡¹ç›®é‡Œæœ‰ï¼‰

```bash
python train.py \
  --arch bilstm \
  --dataroot ./code_dataset \
  --gpu_ids -1 \
  --niter 10 \
  --name exp_bilstm
```

## 3ï¸âƒ£ CodeBERT

```bash
python train.py \
  --arch codebert \
  --dataroot ./code_dataset \
  --gpu_ids -1 \
  --niter 10 \
  --name exp_codebert
```

------

# âœ… Step 3ï¼šå®éªŒ 3 â€”â€” Frozen vs Finetuneï¼ˆåŠ åˆ†é¡¹ï¼‰

------



### ğŸ”¹ Frozen ç‰ˆæœ¬

```python
for p in self.encoder.parameters():
    p.requires_grad = False
```

ä¿å­˜ä¸ºï¼š

```bash
--name exp_codebert_frozen
```

------

### ğŸ”¹ Finetune ç‰ˆæœ¬ï¼ˆä½ ç°åœ¨è¿™ä¸ªï¼‰

```bash
--name exp_codebert_finetune
```

------


è®°å½•ï¼š

| Setting  | Val Acc | Val Loss |
| -------- | ------- | -------- |
| Frozen   | 0.6526  | 0.6440   |
| Finetune | 0.9356  | 0.1499   |

------


        )
        cls = outputs.last_hidden_state[:, 0, :]  # [B, 768]
        logits = self.classifier(cls)
        return logits.squeeze(1)

    
```
